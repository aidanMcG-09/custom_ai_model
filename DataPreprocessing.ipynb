{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO5ztcfB58P3mUXHFclzmtO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"c15f624158d04319ab760f12df44baaa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e97a7ab446ce4ab6ae804388311c932a","IPY_MODEL_e606100ea6c747f4bd35e034bb72336a","IPY_MODEL_9ae2fba596214935b17cde098256cbf0"],"layout":"IPY_MODEL_d6b3826bb526465dbfa8e8b7b43d8202"}},"e97a7ab446ce4ab6ae804388311c932a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a3cedda4125844f5a19c1b7dda9a980f","placeholder":"​","style":"IPY_MODEL_b44f500526b04053b9230362d07a9d7f","value":"Generating train split: "}},"e606100ea6c747f4bd35e034bb72336a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c709d77324874165aafc2ec8df8b8579","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3e98506006eb4bcf802b24ed393f9607","value":1}},"9ae2fba596214935b17cde098256cbf0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_33129c14aa7141a0b030c54277075705","placeholder":"​","style":"IPY_MODEL_ca7f8007ca3a43aea80c8d184ba00f11","value":" 221/0 [00:00&lt;00:00, 1523.66 examples/s]"}},"d6b3826bb526465dbfa8e8b7b43d8202":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3cedda4125844f5a19c1b7dda9a980f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b44f500526b04053b9230362d07a9d7f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c709d77324874165aafc2ec8df8b8579":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"3e98506006eb4bcf802b24ed393f9607":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"33129c14aa7141a0b030c54277075705":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ca7f8007ca3a43aea80c8d184ba00f11":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["This notebook is my process of cleaning and preparing the data for model training. I must convert the mp3 files to wav files, as well as clean the corresponding chat (transcribed) files. The transcriptions are also tokenized."],"metadata":{"id":"02Xlhs2FIBKC"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"okKOsWSgMO7X","executionInfo":{"status":"ok","timestamp":1731012417717,"user_tz":300,"elapsed":24442,"user":{"displayName":"Aidan McGoogan","userId":"18229649277586414586"}},"outputId":"fd039925-0244-4f09-bc87-d2faff1de79f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install torchaudio pandas librosa sentencepiece pydub"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VZwBmvkSNX87","executionInfo":{"status":"ok","timestamp":1731012430386,"user_tz":300,"elapsed":5662,"user":{"displayName":"Aidan McGoogan","userId":"18229649277586414586"}},"outputId":"f1edba78-5924-41bb-b81b-b32b3962be7a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n","Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.2.post1)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.2.0)\n","Collecting pydub\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n","Requirement already satisfied: torch==2.5.0 in /usr/local/lib/python3.10/dist-packages (from torchaudio) (2.5.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchaudio) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchaudio) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchaudio) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchaudio) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchaudio) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchaudio) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch==2.5.0->torchaudio) (1.3.0)\n","Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n","Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.13.1)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.5.2)\n","Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.2)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n","Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.60.0)\n","Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n","Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.2)\n","Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.5.0.post1)\n","Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n","Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.1.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lazy-loader>=0.1->librosa) (24.1)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n","Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.8.30)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.5.0->torchaudio) (3.0.2)\n","Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Installing collected packages: pydub\n","Successfully installed pydub-0.25.1\n"]}]},{"cell_type":"code","source":["!apt-get install ffmpeg -y"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Oe9_qsWCJ2O","executionInfo":{"status":"ok","timestamp":1730738290806,"user_tz":300,"elapsed":3864,"user":{"displayName":"Aidan McGoogan","userId":"18229649277586414586"}},"outputId":"3925208f-4cfc-477e-d2b4-082ab21616af"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n","0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"]}]},{"cell_type":"markdown","source":["This code converts all of my mp3 files to wav files which is what the model requires."],"metadata":{"id":"Uw8gVJ5GIjOA"}},{"cell_type":"code","source":["import os\n","from pydub import AudioSegment\n","\n","# Define paths\n","input_folder = '/content/drive/MyDrive/FinalProject570/Data/mp3data'\n","output_folder = '/content/drive/MyDrive/FinalProject570/Data/wavdata'\n","\n","# Convert all mp3 files to wav and save in the output folder\n","def convert_mp3_to_wav(input_folder, output_folder, sample_rate=16000):\n","    # Ensure output folder exists\n","    os.makedirs(output_folder, exist_ok=True)\n","\n","    # Loop through all files in the input folder\n","    for filename in os.listdir(input_folder):\n","        if filename.endswith('.mp3'):\n","            # Define full path for input and output files\n","            mp3_path = os.path.join(input_folder, filename)\n","            wav_filename = os.path.splitext(filename)[0] + '.wav'\n","            wav_path = os.path.join(output_folder, wav_filename)\n","\n","            # Load and convert the audio\n","            audio = AudioSegment.from_mp3(mp3_path)\n","            audio = audio.set_frame_rate(sample_rate).set_channels(1)  # Set to mono and resample\n","            audio.export(wav_path, format='wav')\n","\n","            print(f'Converted {filename} to {wav_filename}')\n","\n","# Run the conversion function\n","convert_mp3_to_wav(input_folder, output_folder)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BMFoaHjXCrMz","executionInfo":{"status":"ok","timestamp":1730739358049,"user_tz":300,"elapsed":670666,"user":{"displayName":"Aidan McGoogan","userId":"18229649277586414586"}},"outputId":"27ea013b-62ee-4416-dfbb-60a5bd4a1c56"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Converted herring1.mp3 to herring1.wav\n","Converted herring2.mp3 to herring2.wav\n","Converted herring3.mp3 to herring3.wav\n","Converted herring5.mp3 to herring5.wav\n","Converted herring6.mp3 to herring6.wav\n","Converted herring7.mp3 to herring7.wav\n","Converted herring8.mp3 to herring8.wav\n","Converted herring9.mp3 to herring9.wav\n","Converted herring10.mp3 to herring10.wav\n","Converted herring11.mp3 to herring11.wav\n","Converted herring12.mp3 to herring12.wav\n","Converted herring13.mp3 to herring13.wav\n","Converted herring14.mp3 to herring14.wav\n","Converted herring15.mp3 to herring15.wav\n","Converted herring16.mp3 to herring16.wav\n","Converted herring17.mp3 to herring17.wav\n","Converted maria1.mp3 to maria1.wav\n","Converted maria2.mp3 to maria2.wav\n","Converted maria4.mp3 to maria4.wav\n","Converted maria7.mp3 to maria7.wav\n","Converted maria10.mp3 to maria10.wav\n","Converted maria16.mp3 to maria16.wav\n","Converted maria18.mp3 to maria18.wav\n","Converted maria19.mp3 to maria19.wav\n","Converted maria20.mp3 to maria20.wav\n","Converted maria21.mp3 to maria21.wav\n","Converted maria24.mp3 to maria24.wav\n","Converted maria27.mp3 to maria27.wav\n","Converted maria30.mp3 to maria30.wav\n","Converted maria31.mp3 to maria31.wav\n","Converted maria40.mp3 to maria40.wav\n","Converted sastre1.mp3 to sastre1.wav\n","Converted sastre2.mp3 to sastre2.wav\n","Converted sastre3.mp3 to sastre3.wav\n","Converted sastre4.mp3 to sastre4.wav\n","Converted sastre5.mp3 to sastre5.wav\n","Converted sastre6.mp3 to sastre6.wav\n","Converted sastre7.mp3 to sastre7.wav\n","Converted sastre8.mp3 to sastre8.wav\n","Converted sastre9.mp3 to sastre9.wav\n","Converted sastre10.mp3 to sastre10.wav\n","Converted sastre11.mp3 to sastre11.wav\n","Converted sastre12.mp3 to sastre12.wav\n","Converted sastre13.mp3 to sastre13.wav\n","Converted zeledon1.mp3 to zeledon1.wav\n","Converted zeledon2.mp3 to zeledon2.wav\n","Converted zeledon3.mp3 to zeledon3.wav\n","Converted zeledon4.mp3 to zeledon4.wav\n","Converted zeledon5.mp3 to zeledon5.wav\n","Converted zeledon6.mp3 to zeledon6.wav\n","Converted zeledon7.mp3 to zeledon7.wav\n","Converted zeledon8.mp3 to zeledon8.wav\n","Converted zeledon9.mp3 to zeledon9.wav\n","Converted zeledon11.mp3 to zeledon11.wav\n","Converted zeledon13.mp3 to zeledon13.wav\n","Converted zeledon14.mp3 to zeledon14.wav\n"]}]},{"cell_type":"markdown","source":["This next function cleans the chat files I have."],"metadata":{"id":"_PvXcMrTIt59"}},{"cell_type":"code","source":["import os\n","import re\n","\n","# Define the path to the .cha files\n","cha_folder = '/content/drive/MyDrive/FinalProject570/Data/chatdata'\n","\n","def clean_cha_file(cha_file):\n","    \"\"\"\n","    Extract and clean transcription from a .cha file.\n","    \"\"\"\n","    with open(cha_file, 'r') as file:\n","        lines = file.readlines()\n","\n","    # Extract utterances and add language markers as needed\n","    transcription = []\n","    for line in lines:\n","        # Only keep lines that start with \"*\", which indicate actual speech lines\n","        if line.startswith('*'):\n","            # Clean and remove non-speech symbols (this may vary depending on .cha format specifics)\n","            clean_line = re.sub(r'[^\\w\\s<ENG><SPA>]', '', line)\n","            transcription.append(clean_line.strip())\n","\n","    return ' '.join(transcription)\n","\n","# Process each .cha file\n","for filename in os.listdir(cha_folder):\n","    if filename.endswith('.cha'):\n","        cha_path = os.path.join(cha_folder, filename)\n","        transcription = clean_cha_file(cha_path)\n","        print(f\"Processed {filename}:\\n{transcription}\\n\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1BbLSX2IPbgX9juHD6Fp91LnAlr_qiJRU"},"id":"W-57FxzfI1GO","executionInfo":{"status":"ok","timestamp":1730739969536,"user_tz":300,"elapsed":17537,"user":{"displayName":"Aidan McGoogan","userId":"18229649277586414586"}},"outputId":"a434412a-bd77-4f9c-88cc-e782c62e1343"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["Next, I will align the .cha and .wav files in a dictionary data structure so they are organized next to each other."],"metadata":{"id":"cucx3_bnJdSQ"}},{"cell_type":"code","source":["import os\n","\n","# Paths to the .wav and .cha directories\n","wav_folder = '/content/drive/MyDrive/FinalProject570/Data/wavdata'\n","cha_folder = '/content/drive/MyDrive/FinalProject570/Data/chatdata'\n","\n","def create_alignment_dict(wav_folder, cha_folder):\n","    \"\"\"\n","    Creates a dictionary that maps each .wav file to its corresponding .cha transcription file.\n","\n","    Args:\n","        wav_folder (str): Path to the directory containing .wav files.\n","        cha_folder (str): Path to the directory containing .cha files.\n","\n","    Returns:\n","        dict: A dictionary with keys as .wav file paths and values as corresponding .cha file contents.\n","    \"\"\"\n","    alignment_dict = {}\n","\n","    # Get the list of .wav and .cha files\n","    wav_files = [f for f in os.listdir(wav_folder) if f.endswith('.wav')]\n","    cha_files = [f for f in os.listdir(cha_folder) if f.endswith('.cha')]\n","\n","    # Convert cha_files list to a dictionary for quick lookup by filename\n","    cha_dict = {os.path.splitext(f)[0]: os.path.join(cha_folder, f) for f in cha_files}\n","\n","    for wav_file in wav_files:\n","        wav_name = os.path.splitext(wav_file)[0]  # Remove the .wav extension\n","        if wav_name in cha_dict:\n","            # Read the transcription content from the corresponding .cha file\n","            cha_path = cha_dict[wav_name]\n","            with open(cha_path, 'r') as file:\n","                transcription = file.read()\n","            # Store the wav path and cleaned transcription in the dictionary\n","            alignment_dict[os.path.join(wav_folder, wav_file)] = transcription\n","        else:\n","            print(f\"No matching .cha file found for {wav_file}\")\n","\n","    return alignment_dict\n","\n","# Create the alignment dictionary\n","alignment_dict = create_alignment_dict(wav_folder, cha_folder)\n","\n","# Print the first few entries to verify\n","for wav_path, transcription in list(alignment_dict.items())[:5]:\n","    print(f\"WAV file: {wav_path}\\nTranscription: {transcription[:100]}...\\n\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sxy3TfnPJl2I","executionInfo":{"status":"ok","timestamp":1730928164564,"user_tz":300,"elapsed":23737,"user":{"displayName":"Aidan McGoogan","userId":"18229649277586414586"}},"outputId":"c492bc77-0e0b-4b47-e793-a67ecd2324d1"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["WAV file: /content/drive/MyDrive/FinalProject570/Data/wavdata/herring1.wav\n","Transcription: @Font:\tWin95:Lucida Sans Unicode:-16:0\n","@UTF8\n","@Begin\n","@Languages:\teng, spa\n","@Participants:\tLAU Lauren A...\n","\n","WAV file: /content/drive/MyDrive/FinalProject570/Data/wavdata/herring2.wav\n","Transcription: @Font:\tWin95:Arial Unicode MS:-16:0\n","@UTF8\n","@Begin\n","@Languages:\tspa, eng\n","@Participants:\tTOM Tomás Adult...\n","\n","WAV file: /content/drive/MyDrive/FinalProject570/Data/wavdata/herring3.wav\n","Transcription: @Font:\tWin95:Arial:-21:0\n","@UTF8\n","@Begin\n","@Languages:\tspa, eng\n","@Participants:\tASH Ashley Adult, JAC Jack...\n","\n","WAV file: /content/drive/MyDrive/FinalProject570/Data/wavdata/herring5.wav\n","Transcription: @Font:\tWin95:Arial Unicode MS:-21:0\n","@UTF8\n","@Begin\n","@Languages:\tspa, eng\n","@Participants:\tNOA Noah Adult,...\n","\n","WAV file: /content/drive/MyDrive/FinalProject570/Data/wavdata/herring6.wav\n","Transcription: @Font:\tWin95:Arial:-16:0\n","@UTF8\n","@Begin\n","@Languages:\teng, spa\n","@Participants:\tJES Jessica Adult, NIC Nic...\n","\n"]}]},{"cell_type":"markdown","source":["Now that we have the alignment dictionary with .wav file paths and corresponding .cha transcriptions, the next step is to clean and tokenize the transcriptions and prepare them for model training."],"metadata":{"id":"hVQuAhjgJ_GM"}},{"cell_type":"code","source":["import re\n","\n","def clean_transcription(transcription):\n","    \"\"\"\n","    Cleans the transcription by removing unwanted characters and adding language markers.\n","\n","    Args:\n","        transcription (str): Raw transcription text from .cha file.\n","\n","    Returns:\n","        str: Cleaned transcription with language markers.\n","    \"\"\"\n","    # Example: Add language markers (adjust regex for your data if needed)\n","    transcription = re.sub(r'\\[.*?\\]', '', transcription)  # Remove metadata in brackets\n","    transcription = re.sub(r'[^\\w\\s]', '', transcription)  # Remove special characters except spaces\n","    transcription = transcription.replace(\"ENG:\", \"<ENG>\").replace(\"SPA:\", \"<SPA>\")  # Example markers\n","    transcription = re.sub(r'\\s+', ' ', transcription)  # Replace multiple spaces with a single space\n","    return transcription.strip()\n","\n","# Apply cleaning to all transcriptions in the alignment dictionary\n","for wav_path in alignment_dict:\n","    alignment_dict[wav_path] = clean_transcription(alignment_dict[wav_path])\n","\n","# Print a few cleaned transcriptions for verification\n","for wav_path, transcription in list(alignment_dict.items())[:5]:\n","    print(f\"Audio file: {wav_path}\\nCleaned Transcription: {transcription[:100]}...\\n\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wcJ6B2rmKAu1","executionInfo":{"status":"ok","timestamp":1730928171243,"user_tz":300,"elapsed":1017,"user":{"displayName":"Aidan McGoogan","userId":"18229649277586414586"}},"outputId":"71159566-bd37-41e9-8ce6-efaadc666e73"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Audio file: /content/drive/MyDrive/FinalProject570/Data/wavdata/herring1.wav\n","Cleaned Transcription: Font Win95Lucida Sans Unicode160 UTF8 Begin Languages eng spa Participants LAU Lauren Adult CHL Chlo...\n","\n","Audio file: /content/drive/MyDrive/FinalProject570/Data/wavdata/herring2.wav\n","Cleaned Transcription: Font Win95Arial Unicode MS160 UTF8 Begin Languages spa eng Participants TOM Tomás Adult MIG Miguel A...\n","\n","Audio file: /content/drive/MyDrive/FinalProject570/Data/wavdata/herring3.wav\n","Cleaned Transcription: Font Win95Arial210 UTF8 Begin Languages spa eng Participants ASH Ashley Adult JAC Jack Adult OSE non...\n","\n","Audio file: /content/drive/MyDrive/FinalProject570/Data/wavdata/herring5.wav\n","Cleaned Transcription: Font Win95Arial Unicode MS210 UTF8 Begin Languages spa eng Participants NOA Noah Adult MEG Megan Adu...\n","\n","Audio file: /content/drive/MyDrive/FinalProject570/Data/wavdata/herring6.wav\n","Cleaned Transcription: Font Win95Arial160 UTF8 Begin Languages eng spa Participants JES Jessica Adult NIC Nicholas Adult ID...\n","\n"]}]},{"cell_type":"code","source":["!pip install tokenizers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KuxYcYG4XjDc","executionInfo":{"status":"ok","timestamp":1730928333635,"user_tz":300,"elapsed":4027,"user":{"displayName":"Aidan McGoogan","userId":"18229649277586414586"}},"outputId":"182fe226-9017-4349-fd41-6d159766b249"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.19.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers) (0.24.7)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (3.16.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2024.10.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.66.6)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2024.8.30)\n"]}]},{"cell_type":"code","source":["from tokenizers import Tokenizer, models, trainers, pre_tokenizers\n","from tokenizers.pre_tokenizers import Whitespace\n","\n","# Load and prepare transcriptions\n","with open('transcriptions.txt', 'r') as f:\n","    lines = [line.strip() for line in f if line.strip()]\n","\n","# Initialize BPE tokenizer\n","tokenizer = Tokenizer(models.BPE())\n","tokenizer.pre_tokenizer = Whitespace()\n","\n","# Train tokenizer on your transcriptions\n","trainer = trainers.BpeTrainer(vocab_size=8000, min_frequency=2, special_tokens=[\"<PAD>\", \"<UNK>\", \"<ENG>\", \"<SPA>\"])\n","tokenizer.train_from_iterator(lines, trainer)\n","\n","# Save the tokenizer model\n","tokenizer.save(\"bpe_tokenizer.json\")\n","\n","# Example: Tokenize a sample text\n","encoding = tokenizer.encode(\"This is an example sentence.\")\n","print(\"Tokenized:\", encoding.tokens)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rhd1nMGyXlsb","executionInfo":{"status":"ok","timestamp":1730928360150,"user_tz":300,"elapsed":8504,"user":{"displayName":"Aidan McGoogan","userId":"18229649277586414586"}},"outputId":"004c6d6f-bd90-4456-a38b-d4b7d38bafdf"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenized: ['T', 'his', 'is', 'an', 'example', 'sent', 'ence']\n"]}]},{"cell_type":"code","source":["!pip install nltk"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XKjByZ3kYN50","executionInfo":{"status":"ok","timestamp":1730928509356,"user_tz":300,"elapsed":4631,"user":{"displayName":"Aidan McGoogan","userId":"18229649277586414586"}},"outputId":"e8600cd1-4a9f-486a-fd6c-363ce9186cb1"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n"]}]},{"cell_type":"code","source":["import nltk\n","from nltk.tokenize import word_tokenize\n","from collections import Counter\n","\n","# Download necessary NLTK data\n","nltk.download('punkt')\n","\n","# Load transcriptions from the alignment dictionary (you already have this)\n","lines = list(alignment_dict.values())\n","\n","# Tokenize all transcriptions at the word level\n","all_tokens = []\n","for line in lines:\n","    tokens = word_tokenize(line.lower())  # Tokenize and make lowercase for consistency\n","    all_tokens.extend(tokens)\n","\n","# Build vocabulary with a fixed size\n","vocab_size = 8000\n","vocab = [token for token, _ in Counter(all_tokens).most_common(vocab_size)]\n","\n","# Create a vocabulary dictionary for token-to-id mapping\n","vocab_dict = {token: idx for idx, token in enumerate(vocab, start=1)}  # Start indexing from 1\n","\n","# Define a function to convert sentences to token IDs\n","def text_to_token_ids(text, vocab_dict, unknown_token=0):\n","    tokens = word_tokenize(text.lower())\n","    token_ids = [vocab_dict.get(token, unknown_token) for token in tokens]\n","    return token_ids\n","\n","# Example usage\n","example_text = \"This is an example sentence.\"\n","token_ids = text_to_token_ids(example_text, vocab_dict)\n","print(\"Token IDs:\", token_ids)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sniIWLtPYUp1","executionInfo":{"status":"ok","timestamp":1730928544092,"user_tz":300,"elapsed":11186,"user":{"displayName":"Aidan McGoogan","userId":"18229649277586414586"}},"outputId":"391d668c-71e3-4e83-c16c-17a5bd03febe"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"stream","name":"stdout","text":["Token IDs: [84, 27, 248, 1708, 0, 0]\n"]}]},{"cell_type":"code","source":["import json\n","\n","# Create a list to store the (audio_path, token_ids) pairs\n","training_data = []\n","\n","for wav_path, transcription in alignment_dict.items():\n","    token_ids = text_to_token_ids(transcription, vocab_dict)\n","    training_data.append({\n","        \"audio_path\": wav_path,\n","        \"token_ids\": token_ids\n","    })\n","\n","output_path = '/content/drive/MyDrive/FinalProject570/training_data.json'\n","with open(output_path, 'w') as f:\n","    json.dump(training_data, f)\n","\n","print(f\"Training data saved as '{output_path}'.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vguAQjeCYict","executionInfo":{"status":"ok","timestamp":1730928721997,"user_tz":300,"elapsed":5955,"user":{"displayName":"Aidan McGoogan","userId":"18229649277586414586"}},"outputId":"3ca19a8f-4977-4e4d-9a56-201819cb8ec3"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Training data saved as '/content/drive/MyDrive/FinalProject570/training_data.json'.\n"]}]},{"cell_type":"code","source":["!pip install transformers datasets soundfile"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tDp1vMNCcJvc","executionInfo":{"status":"ok","timestamp":1730929541301,"user_tz":300,"elapsed":6328,"user":{"displayName":"Aidan McGoogan","userId":"18229649277586414586"}},"outputId":"7ba82e46-fa5e-4abc-962f-3128f3bdcb7a"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n","Collecting datasets\n","  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (0.12.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n","  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile) (1.17.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile) (2.22)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n","Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2024.10.0\n","    Uninstalling fsspec-2024.10.0:\n","      Successfully uninstalled fsspec-2024.10.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"]}]},{"cell_type":"code","source":["import json\n","from datasets import Dataset, Audio\n","\n","# Load training data from Google Drive\n","data_path = '/content/drive/MyDrive/FinalProject570/training_data.json'\n","with open(data_path, 'r') as f:\n","    training_data = json.load(f)\n","\n","# Convert to Hugging Face Dataset format\n","dataset = Dataset.from_dict({\n","    \"audio_path\": [entry[\"audio_path\"] for entry in training_data],\n","    \"transcription\": [entry[\"token_ids\"] for entry in training_data]\n","})\n","\n","# Add audio column using file paths\n","dataset = dataset.cast_column(\"audio_path\", Audio(sampling_rate=16000))"],"metadata":{"id":"8Xq_LtYFcNFz","executionInfo":{"status":"ok","timestamp":1730929573395,"user_tz":300,"elapsed":3549,"user":{"displayName":"Aidan McGoogan","userId":"18229649277586414586"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["!rm -rf ~/.cache/huggingface"],"metadata":{"id":"4rJsgxIxd2c7","executionInfo":{"status":"ok","timestamp":1730929981610,"user_tz":300,"elapsed":233,"user":{"displayName":"Aidan McGoogan","userId":"18229649277586414586"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["!huggingface-cli login"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y2o6R74ngomF","executionInfo":{"status":"ok","timestamp":1730992063977,"user_tz":300,"elapsed":92546,"user":{"displayName":"Aidan McGoogan","userId":"18229649277586414586"}},"outputId":"9f807172-7d9a-41c4-dfcb-237e92c4ae80"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n","    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n","    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n","    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n","    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n","\n","    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n","Enter your token (input will not be visible): \n","Add token as git credential? (Y/n) n\n","Token is valid (permission: fineGrained).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]}]},{"cell_type":"code","source":["cha_path = '/content/drive/MyDrive/FinalProject570/Data/chatdata/sastre3.cha'\n","wav_path = '/content/drive/MyDrive/FinalProject570/Data/wavdata/sastre3.wav'\n","output_dir = '/content/drive/MyDrive/FinalProject570/Data/segments'  # Directory to save segmented audio files\n"],"metadata":{"id":"WC4j4novKU2L","executionInfo":{"status":"ok","timestamp":1730992097261,"user_tz":300,"elapsed":149,"user":{"displayName":"Aidan McGoogan","userId":"18229649277586414586"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import os\n","import re\n","from pydub import AudioSegment\n","\n","# Ensure the output directory exists\n","os.makedirs(output_dir, exist_ok=True)\n","\n","# Define regex to match timestamps and language markers\n","timestamp_pattern = re.compile(r\"\u0015(\\d+)_(\\d+)\u0015\")\n","language_pattern = re.compile(r\"@s:(eng|spa)\")\n","\n","def parse_cha_file(cha_path):\n","    segments = []\n","    current_language = None\n","\n","    with open(cha_path, 'r', encoding='utf-8') as file:\n","        for line in file:\n","            # Check if line contains a timestamp and a language marker\n","            timestamp_match = timestamp_pattern.search(line)\n","            language_match = language_pattern.search(line)\n","\n","            if timestamp_match and language_match:\n","                start_time = int(timestamp_match.group(1))\n","                end_time = int(timestamp_match.group(2))\n","                language = language_match.group(1)  # 'eng' or 'spa'\n","\n","                # Add segment info to list\n","                segments.append({\n","                    'start_time': start_time,\n","                    'end_time': end_time,\n","                    'language': 0 if language == 'eng' else 1  # 0 for English, 1 for Spanish\n","                })\n","\n","    return segments\n","\n","# Parse the .cha file to get labeled segments\n","segments = parse_cha_file(cha_path)\n","print(f\"Parsed {len(segments)} segments.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"24BlPeTUK4WC","executionInfo":{"status":"ok","timestamp":1730992146512,"user_tz":300,"elapsed":1086,"user":{"displayName":"Aidan McGoogan","userId":"18229649277586414586"}},"outputId":"40f2d604-d48b-4bf4-f838-71c8e9889fe2"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Parsed 221 segments.\n"]}]},{"cell_type":"code","source":["# Load the full audio file\n","audio = AudioSegment.from_wav(wav_path)\n","\n","def save_segments(audio, segments, output_dir):\n","    for i, segment in enumerate(segments):\n","        start = segment['start_time']\n","        end = segment['end_time']\n","        language = segment['language']\n","\n","        # Extract the audio segment\n","        audio_segment = audio[start:end]\n","\n","        # Save the audio segment with a language label in the filename\n","        segment_filename = f\"sastre3_segment_{i}_lang_{language}.wav\"\n","        audio_segment.export(os.path.join(output_dir, segment_filename), format=\"wav\")\n","\n","# Save segments to the output directory\n","save_segments(audio, segments, output_dir)\n","print(f\"Saved segmented audio files to {output_dir}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oOvhCakWLGb5","executionInfo":{"status":"ok","timestamp":1730992177800,"user_tz":300,"elapsed":3916,"user":{"displayName":"Aidan McGoogan","userId":"18229649277586414586"}},"outputId":"b9b6f8b3-b268-43b6-83b7-dc5a139514d9"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Saved segmented audio files to /content/drive/MyDrive/FinalProject570/Data/segments\n"]}]},{"cell_type":"code","source":["!pip install datasets transformers soundfile\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RPGGU8P_LfId","executionInfo":{"status":"ok","timestamp":1730992281444,"user_tz":300,"elapsed":5916,"user":{"displayName":"Aidan McGoogan","userId":"18229649277586414586"}},"outputId":"630f2ea8-e7f4-4584-9f42-604d7cef86f4"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets\n","  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n","Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (0.12.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n","  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n","Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile) (1.17.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile) (2.22)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n","Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2024.10.0\n","    Uninstalling fsspec-2024.10.0:\n","      Successfully uninstalled fsspec-2024.10.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"]}]},{"cell_type":"code","source":["import json\n","import os\n","\n","# Define the output JSON file path\n","json_path = '/content/drive/MyDrive/FinalProject570/Data/training_data.json'\n","\n","# Gather paths and labels for each segmented audio file\n","data = []\n","for filename in os.listdir(output_dir):\n","    if filename.endswith('.wav'):\n","        # Extract the language label from the filename\n","        label = int(filename.split('_')[-1].replace('.wav', ''))\n","\n","        # Append file info and label to the data list\n","        data.append({\n","            'audio_path': os.path.join(output_dir, filename),\n","            'label': label  # 0 for English, 1 for Spanish\n","        })\n","\n","# Save the data to a JSON file\n","with open(json_path, 'w') as f:\n","    json.dump(data, f)\n","\n","print(f\"Training data saved to {json_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8GzrHvyrLkEb","executionInfo":{"status":"ok","timestamp":1730992329037,"user_tz":300,"elapsed":171,"user":{"displayName":"Aidan McGoogan","userId":"18229649277586414586"}},"outputId":"e7f832c5-1a3b-4624-f7fd-d819d33c566f"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Training data saved to /content/drive/MyDrive/FinalProject570/Data/training_data.json\n"]}]},{"cell_type":"code","source":["from datasets import load_dataset, Audio\n","\n","# Load the dataset from the JSON file\n","dataset = load_dataset('json', data_files=json_path, split='train')\n","\n","# Cast the audio_path column to Audio type for processing\n","dataset = dataset.cast_column('audio_path', Audio(sampling_rate=16000))\n","\n","# Verify the dataset structure\n","print(dataset)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":118,"referenced_widgets":["c15f624158d04319ab760f12df44baaa","e97a7ab446ce4ab6ae804388311c932a","e606100ea6c747f4bd35e034bb72336a","9ae2fba596214935b17cde098256cbf0","d6b3826bb526465dbfa8e8b7b43d8202","a3cedda4125844f5a19c1b7dda9a980f","b44f500526b04053b9230362d07a9d7f","c709d77324874165aafc2ec8df8b8579","3e98506006eb4bcf802b24ed393f9607","33129c14aa7141a0b030c54277075705","ca7f8007ca3a43aea80c8d184ba00f11"]},"id":"6FW5BjOOLwk_","executionInfo":{"status":"ok","timestamp":1730992349772,"user_tz":300,"elapsed":3059,"user":{"displayName":"Aidan McGoogan","userId":"18229649277586414586"}},"outputId":"efe7bf25-d23d-43f9-be5c-03bc0da8095b"},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c15f624158d04319ab760f12df44baaa"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset({\n","    features: ['audio_path', 'label'],\n","    num_rows: 221\n","})\n"]}]}]}